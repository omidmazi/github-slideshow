{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adad.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP0DHiddGtffkxJs6emjsXq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omidmazi/github-slideshow/blob/master/CNN-Persian%20number.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkYAsc7m3LIt"
      },
      "source": [
        "from skimage import io,transform\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import model_from_json\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Rwuzf_VDyv"
      },
      "source": [
        "def predict_digit(filename):\n",
        "  #Your code to predict the value given the image filename\n",
        "  #Read an image as follows:\n",
        "  img = io.imread('photo/3.jpg')\n",
        "  print(f'Original image shape {img.shape}')\n",
        "  plt.imshow(img)\n",
        "  #Convert to grayscale\n",
        "  def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:], [0.2989, 0.5870, 0.1140])\n",
        "  gray = rgb2gray(img)    \n",
        "  plt.imshow(gray, cmap='gray')\n",
        "  plt.show()\n",
        "  #Resize to 28 x 28 pixels\n",
        "  gray28x28 = transform.resize(gray, (28, 28))\n",
        "  print(f'Resized image shape {gray28x28.shape}')\n",
        "  plt.imshow(gray28x28, cmap='gray')\n",
        "  #Filter the background\n",
        "  vectorized_filter = np.vectorize(lambda v: 255 if v > 112 else v)\n",
        "  filtered = vectorized_filter(gray28x28)\n",
        "  plt.imshow(filtered, cmap='gray')\n",
        "  #Invert the image and scale pixel values\n",
        "  inverted = 255 - filtered\n",
        "  reshaped = inverted.reshape(28, 28, 1) / 255.0\n",
        "  batch = np.array([reshaped])\n",
        "  plt.imshow(inverted, cmap='gray')\n",
        "  #definemodel\n",
        "  model=keras.Sequential()\n",
        "  model.add(Dense(units=200,input_dim=1))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(units=20))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(units=1))\n",
        "  #Make a prediction\n",
        "  predictions = model.predict(batch)\n",
        "  most_likely = predictions.argmax(1)\n",
        "  most_likely\n",
        "  return prediction\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvrXHo-WZJG3"
      },
      "source": [
        "\n",
        "\n",
        "plt.bar(range(10), predictions[0], tick_label=range(10))\n",
        "plt.title('Prediction values')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}